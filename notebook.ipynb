{"cells":[{"cell_type":"code","execution_count":1,"id":"tbUUto8sAtr1","metadata":{"id":"tbUUto8sAtr1","executionInfo":{"status":"ok","timestamp":1740640856941,"user_tz":-480,"elapsed":39441,"user":{"displayName":"周敬淇","userId":"02105256288629143054"}}},"outputs":[],"source":["from typing import Callable\n","# 忽略\"reportGeneralTypeIssues\"检查，`override`是有效的导入符号。\n","from typing_extensions import override  # type: ignore\n","import io\n","import os\n","import pickle\n","import random\n","import zipfile\n","\n","from torch import nn\n","from torch.nn import functional as F\n","from torch.utils import data\n","from torchvision.transforms import v2\n","from tqdm import notebook\n","import numpy as np\n","import torch\n","\n","from google.colab import auth, userdata\n","from googleapiclient import discovery, http\n","\n","# 批准此笔记本访问用户 Google API，用户须已将 DEAP 数据集的存档文件托管于\n","# Google 云端硬盘并知晓其文件标识符。\n","auth.authenticate_user()"]},{"cell_type":"code","execution_count":2,"id":"nCb4ubjnIcBm","metadata":{"id":"nCb4ubjnIcBm","executionInfo":{"status":"ok","timestamp":1740641199477,"user_tz":-480,"elapsed":113,"user":{"displayName":"周敬淇","userId":"02105256288629143054"}}},"outputs":[],"source":["class DEAPdataset(data.Dataset):\n","    \"\"\"[**使用脑电图、生理和视频信号进行情绪分析的数据集**](https://www.eecs.qmul.ac.uk/mmv/datasets/deap/readme.html)，简称\"DEAP 数据集\"。\n","\n","    研究者在 32 名受试者分别观看 40 段一分钟长的音乐视频片段时，记录了他们的脑\n","    电图和周围生理信号，详情按[_DEAP：使用生理信号进行情绪分析的数据库（译）_](https://www.eecs.qmul.ac.uk/mmv/datasets/deap/doc/tac_special_issue_2011.pdf)。\n","\n","    DEAP 数据集在`data_preprocessed_python.zip`存档文件中发布了经以下预处理的脑\n","    电图数据：\n","\n","        1. 将原始脑电图信号降采样至 128 赫兹。\n","        2. 滤除眼电图扰动。\n","        3. 实施 4 至 45 赫兹带通滤波并根据公共参考取均值。\n","        4. 逐 60 秒划分试次，删除 3 秒试次前基线。\n","        5. 依照日内瓦顺序将数据通道重新排列。\n","\n","    我们的数据下载机能假设用户的 Google 云端硬盘中托管有此存档文件，并为其标识符\n","    建立名称为`DEAP_ARCHIVE_ID`的 Colab Serect。\n","    \"\"\"\n","    # 每位受试者参与脑电图采集的试次数。\n","    TRIALS_PER_SUBJECT = 40\n","    # 参与脑电图采集的受试者总数。\n","    TOTAL_SUBJECT_NUM = 32\n","\n","    # Google 云端硬盘为存档的数据集文件`data_preprocessed_python.zip`分配的唯一\n","    # 文件标识符。\n","    _COLAB_SECRET_NAME = 'DEAP_ARCHIVE_ID'\n","    # 每试次数据仅前 32 通道直接来自于各脑电极。\n","    _USING_DATA_SLICE = np.s_[:, 0:32, :]\n","\n","    def __init__(\n","        self,\n","        root: str | os.PathLike[str] = 'data',\n","        split: str = 'train',\n","        transforms: Callable[[torch.Tensor], torch.Tensor] | None = None,\n","        download: bool = False,\n","    ) -> None:\n","        \"\"\"尝试发现或下载存档文件`data_preprocessed_python.zip`，并从中加载指定\n","        的 DEAP 数据集划分，每样本包含一个试次。\n","\n","        参数：\n","            `root`：存放所属项目数据集的根目录。\n","\n","            `split`：期望加载的数据划分，可能的划分包括\"train\"、\"val\" 和\"test\"。\n","                数据划分以受试者为单位，依照 train/val/test=2:1:1 的比例实施。\n","\n","            `transforms`：向每笔样本（试次）的脑电图数据附加的用户预处理。\n","\n","            `download`：随实例化将存档于 Google 云端硬盘的数据集文件下载到环境并\n","                解压缩。\n","        \"\"\"\n","        super().__init__()\n","        self.root = os.path.expanduser(os.fspath(root))\n","        self.split = split\n","        self.transforms = transforms\n","        self._base_folder = os.path.join(self.root, 'DEAPdataset')\n","        self._data_folder = os.path.join(\n","            self._base_folder, 'data_preprocessed_python')\n","        self._data_archive = self._data_folder + '.zip'\n","\n","        if download:\n","            self.download()\n","\n","        if not self._check_exists():\n","            raise RuntimeError(\n","                '找不到数据集，你可以指定参数 `download=True` 下载它。')\n","\n","        self.data: list[torch.Tensor] = []\n","        self.label: list[int] = []\n","\n","        data_files: list[str] = []\n","\n","        for sub_id in range(1, 1 + self.TOTAL_SUBJECT_NUM):\n","            data_file = os.path.join(self._data_folder, f\"s{sub_id:02d}.dat\")\n","            data_files.append(data_file)\n","        random.shuffle(data_files)\n","\n","        match self.split:\n","            case 'train':\n","                data_files = data_files[:24]\n","            case 'val':\n","                data_files = data_files[24:28]\n","            case 'test':\n","                data_files = data_files[28:]\n","            case _:\n","                raise ValueError(\n","                    f\"参数 `split` 取得非法值 \\\"{split}\\\"，\"\n","                    \"有效值为 \\\"train\\\"、\\\"val\\\" 和 \\\"test\\\"。\",\n","                )\n","        self._load_data(data_files)\n","\n","    def _load_data(self, data_files: list[str]) -> None:\n","        for data_file in data_files:\n","            self.label.append(int(os.path.basename(data_file)[1:3]))\n","            with open(data_file, 'rb') as dat:\n","                raw_data = pickle.load(dat, encoding='latin1')['data']\n","                data = torch.from_numpy(\n","                    raw_data[self._USING_DATA_SLICE].copy())\n","                self.data.append(data.to(torch.float))\n","\n","    def __len__(self) -> int:\n","        return len(self.data) * self.TRIALS_PER_SUBJECT\n","\n","    def _check_exists(self) -> bool:\n","        return os.path.isdir(self._data_folder)\n","\n","    def download(self) -> None:\n","        \"\"\"从 Google 云端硬盘下载`data_preprocessed_python.zip`文件并解压缩\"\"\"\n","\n","        if self._check_exists():\n","            return\n","\n","        os.makedirs(self._base_folder, exist_ok=True)\n","        with (\n","            discovery.build('drive', 'v3') as drive_service,\n","            io.FileIO(self._data_archive, mode='wb') as downloaded,\n","        ):\n","            request = drive_service.files().get_media(\n","                fileId=userdata.get(self._COLAB_SECRET_NAME))\n","            downloader = http.MediaIoBaseDownload(downloaded, request)\n","            self._download_media(downloader)\n","\n","        with zipfile.ZipFile(self._data_archive) as zf:\n","            zf.extractall(self._base_folder)\n","\n","    def _download_media(self, downloader: http.MediaIoBaseDownload) -> None:\n","        KILOBYTE_IN_BYTES = 1024\n","        with notebook.tqdm(\n","            desc='数据下载中', unit='千字节', dynamic_ncols=True) as pbar:\n","            done = False\n","            last_progress = 0\n","            while not done:\n","                status, done = downloader.next_chunk()\n","                if last_progress == 0 and status.total_size is not None:\n","                    pbar.reset(total=status.total_size // KILOBYTE_IN_BYTES)\n","                chunk_size = status.resumable_progress - last_progress\n","                pbar.update(chunk_size // KILOBYTE_IN_BYTES)\n","                last_progress = status.resumable_progress\n","\n","    @override\n","    def __getitem__(self, index: int) -> tuple[torch.Tensor, int]:\n","        subject_idx, trial_idx = divmod(index, self.TRIALS_PER_SUBJECT)\n","        data = torch.select(self.data[subject_idx], dim=0, index=trial_idx)\n","\n","        if self.transforms is not None:\n","            data = self.transforms(data)\n","\n","        return data, self.label[subject_idx]"]},{"cell_type":"code","source":["class SENet(nn.Module):\n","    \"\"\"挤压-激励网络（Squeeze-and-Excitation Network, SENet）的复现。\n","\n","    挤压-激励网络的目标是通过明确建模卷积特征通道之间的相互依赖关系来提高网络的\n","    表示能力。其机制受注意力/自门控启发，使网络能够执行特征重校准：学习使用全局\n","    信息选择性地强调有信息量的特征并抑制不太有用的特征。此模块由[挤压激励网络（译）](https://doi.org/10.1109/CVPR.2018.00745)\n","    一文首次提出，所提供的[开源代码](https://github.com/hujie-frank/SENet)基于 CUDA/C++ 编程实现。\n","\n","    挤压-激励网络由以下步骤顺次构成：\n","\n","        1. 挤压：对输入特征图沿通道实施全局池化，将空间维度信息压缩为通道描述\n","        符，捕获全局上下文。\n","        2. 激励：根据挤压步骤得出的描述符，学习针对通道级别的门控权重。这是通过一个具比例收缩隐层的两层感知机实现的，其中隐层由线性整流函数激活，而门控\n","        权重由逻辑斯谛函数计算感知机输出得到。\n","        3. 缩放：将门控权重作用于原始输入特征图，使网络能够\"关注\"重要通道，\"忽略\n","        \"不相关通道。\n","\n","    一般认为，该网络的创新点包括计算负载低、易于集成到现有架构和基于输入的通道权\n","    重动态适应。\n","    \"\"\"\n","    def __init__(self, num_channels: int, reduction_ratio: int = 16) -> None:\n","        \"\"\"\n","        \"\"\"\n","        super().__init__()\n","        self.num_channels = num_channels\n","        self.reduction_ratio = reduction_ratio\n","\n","        self.sq = nn.AdaptiveAvgPool2d(1)\n","        # 忽略`reportGeneralTypeIssues`检查，由`nn.Module`构成的列表是合法的\n","        # `nn.Sequential`实例初始化参数。\n","        self.ex = nn.Sequential(\n","            nn.Linear(\n","                num_channels, num_channels // reduction_ratio, bias=False), #type: ignore\n","            nn.ReLU(),\n","            nn.Linear(\n","                num_channels // reduction_ratio, num_channels, bias=False),\n","            nn.Sigmoid(),\n","        )\n","\n","    @override\n","    def forward(self, u: torch.Tensor) -> torch.Tensor:\n","        self._validate_channel(u)\n","        return u @ torch.diag(self.ex(self.sq(u)))\n","\n","    def _validate_channel(self, u: torch.Tensor) -> None:\n","        in_channels = u.shape[0] if len(u.shape) == 2 else u.shape[1]\n","        if in_channels != self.num_channels:\n","            raise ValueError(f\"声明的特征通道数（{self.num_channels}）\"\n","                f\"与实际张量的通道数（{in_channels}）不符。\")"],"metadata":{"id":"gBUNO1WuwzNu"},"id":"gBUNO1WuwzNu","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TODO: 完成骨干网络。\n","class Block(nn.Module):\n","    def __init__(self, in_channels: int) -> None:\n","        super().__init__()\n","        self.conv = nn.Conv1d(in_channels, )\n","\n","    @override\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        return x"],"metadata":{"id":"F8ZdfFse2XsY"},"id":"F8ZdfFse2XsY","execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.2"}},"nbformat":4,"nbformat_minor":5}